{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nnp.random.seed(42)\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom skimage import color\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:35.500005Z","iopub.execute_input":"2023-05-28T21:46:35.500277Z","iopub.status.idle":"2023-05-28T21:46:40.780863Z","shell.execute_reply.started":"2023-05-28T21:46:35.500252Z","shell.execute_reply":"2023-05-28T21:46:40.779734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = random.randint(50, 100)\nmy_list = [512]\nbatch_size = random.choice(my_list)\nlearning_rate = 1e-3\nuse_gpu = True\nnum_workers = 2\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\nprint(\"num_epochs:\" + str(num_epochs))\nprint(\"batch_size:\" + str(batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:40.786673Z","iopub.execute_input":"2023-05-28T21:46:40.789710Z","iopub.status.idle":"2023-05-28T21:46:40.836102Z","shell.execute_reply.started":"2023-05-28T21:46:40.789675Z","shell.execute_reply":"2023-05-28T21:46:40.835084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, d=128):\n        super(Net, self).__init__()\n            \n        self.encoder = nn.Sequential(\n                nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),\n                nn.BatchNorm2d(32),\n                nn.LeakyReLU(0.2),\n                nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n                nn.LeakyReLU(0.2),\n                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm2d(64),\n                nn.LeakyReLU(0.2),\n                nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n                nn.BatchNorm2d(128),\n                nn.LeakyReLU(0.2)\n            )\n\n        self.conv_stack = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, dilation=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, dilation=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2)\n        )\n\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.2),\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.ConvTranspose2d(32, 2, kernel_size=4, stride=2, padding=1),\n        )\n\n        # Randomly initialize the parameters\n        self.initialize_parameters()\n\n    def initialize_parameters(self):\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.Linear):\n                init.xavier_uniform_(module.weight)\n                if module.bias is not None:\n                    init.zeros_(module.bias)\n\n    def forward(self, input):\n        x = self.encoder(input)\n        x = self.conv_stack(x)\n        x = self.decoder(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:40.837395Z","iopub.execute_input":"2023-05-28T21:46:40.837885Z","iopub.status.idle":"2023-05-28T21:46:40.865315Z","shell.execute_reply.started":"2023-05-28T21:46:40.837848Z","shell.execute_reply":"2023-05-28T21:46:40.864327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RandomAproach(nn.Module):\n    def __init__(self, color_net, num_classes=10):\n        super(RandomAproach, self).__init__()\n        self.color_net = color_net.encoder\n        self.conv1 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n        self.dropout1 = nn.Dropout(0.5)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n        self.dropout2 = nn.Dropout(0.5)\n        self.relu3 = nn.ReLU()\n        self.classifier = nn.Linear(128 * 4 * 4, num_classes)\n\n        # Randomly initialize the parameters\n        self.initialize_parameters()\n\n    def initialize_parameters(self):\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n                init.xavier_uniform_(module.weight)\n                init.zeros_(module.bias)\n\n    def forward(self, input):\n        x = self.color_net(input[:, :1, :, :])  # Pass only the first channel to color_net.encoder\n        x = self.conv1(x)\n        x = self.dropout1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.conv3(x)\n        x = self.dropout2(x)\n        x = self.relu3(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n    \nnet = Net()\n\nmodel = RandomAproach(net, num_classes=10).to(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-28T21:46:40.870307Z","iopub.execute_input":"2023-05-28T21:46:40.872945Z","iopub.status.idle":"2023-05-28T21:46:43.852487Z","shell.execute_reply.started":"2023-05-28T21:46:40.872915Z","shell.execute_reply":"2023-05-28T21:46:43.851612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def import_image(img):\n    return torch.FloatTensor(np.expand_dims(color.rgb2(np.array(img)), axis=0))\n\nimg_transform = transforms.Compose([\n    transforms.ToTensor()\n])\n\ntrain_dataset = datasets.CIFAR10('./data/CIFAR10', train=True, transform=img_transform, target_transform=None, download=True)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntest_dataset = datasets.CIFAR10('./data/CIFAR10', train=False, transform=img_transform, target_transform=None, download=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:43.855705Z","iopub.execute_input":"2023-05-28T21:46:43.856059Z","iopub.status.idle":"2023-05-28T21:46:50.957334Z","shell.execute_reply.started":"2023-05-28T21:46:43.856025Z","shell.execute_reply":"2023-05-28T21:46:50.956404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = list(range(len(test_dataset)))\nnp.random.shuffle(indices)\n\ntest_size = 0.2 * len(indices)\nsplit = int(np.floor(test_size))\nval_idx, test_idx = indices[split:], indices[:split]\n\nval_sampler = SubsetRandomSampler(val_idx)\ntest_sampler = SubsetRandomSampler(test_idx)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\nvalidation_dataloader = DataLoader(test_dataset, sampler=val_sampler, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\ntest_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1, shuffle=False, num_workers=num_workers, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:50.958819Z","iopub.execute_input":"2023-05-28T21:46:50.959154Z","iopub.status.idle":"2023-05-28T21:46:50.967233Z","shell.execute_reply.started":"2023-05-28T21:46:50.959122Z","shell.execute_reply":"2023-05-28T21:46:50.966210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss() # already includes the Softmax activation\noptimizer =  torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:50.968449Z","iopub.execute_input":"2023-05-28T21:46:50.969423Z","iopub.status.idle":"2023-05-28T21:46:50.978399Z","shell.execute_reply.started":"2023-05-28T21:46:50.969392Z","shell.execute_reply":"2023-05-28T21:46:50.977571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n    if is_train:\n      assert optimizer is not None, \"When training, please provide an optimizer.\"\n      \n    num_batches = len(dataloader)\n\n    if is_train:\n      model.train() # put model in train mode\n    else:\n      model.eval()\n\n    total_loss = 0.0\n    preds = []\n    labels = []\n\n    with torch.set_grad_enabled(is_train):\n      for batch, (X, y) in enumerate(tqdm(dataloader)):\n          X, y = X.to(device), y.to(device)\n\n          # Compute prediction error\n          pred = model(X)\n          loss = loss_fn(pred, y)\n\n          if is_train:\n            # Backpropagation\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n          # Save training metrics\n          total_loss += loss.item() # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n\n          probs = F.softmax(pred, dim=1)\n          final_pred = torch.argmax(probs, dim=1)\n          preds.extend(final_pred.cpu().numpy())\n          labels.extend(y.cpu().numpy())\n\n    return total_loss / num_batches, accuracy_score(labels, preds)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:50.979617Z","iopub.execute_input":"2023-05-28T21:46:50.979995Z","iopub.status.idle":"2023-05-28T21:46:50.990770Z","shell.execute_reply.started":"2023-05-28T21:46:50.979963Z","shell.execute_reply":"2023-05-28T21:46:50.989833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 25\ntrain_history = {'loss': [], 'accuracy': []}\nval_history = {'loss': [], 'accuracy': []}\nbest_val_loss = np.inf\nprint(\"Start training...\")\nfor t in range(num_epochs):\n    print(f\"\\nEpoch {t+1}\")\n    train_loss, train_acc = epoch_iter(train_dataloader, model, loss_fn, optimizer)\n    print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n    val_loss, val_acc = epoch_iter(validation_dataloader, model, loss_fn, is_train=False)\n    print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n\n    # save model when val loss improves\n    if val_loss < best_val_loss:\n      best_val_loss = val_loss\n      save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n      torch.save(save_dict, 'best_model.pth')\n\n    # save latest model\n    save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n    torch.save(save_dict, 'latest_model.pth')\n\n    # save training history for plotting purposes\n    train_history[\"loss\"].append(train_loss)\n    train_history[\"accuracy\"].append(train_acc)\n\n    val_history[\"loss\"].append(val_loss)\n    val_history[\"accuracy\"].append(val_acc)\n    \nprint(\"Finished\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:46:50.992871Z","iopub.execute_input":"2023-05-28T21:46:50.993577Z","iopub.status.idle":"2023-05-28T21:50:18.683373Z","shell.execute_reply.started":"2023-05-28T21:46:50.993530Z","shell.execute_reply":"2023-05-28T21:50:18.682233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_errors(model, dataloader, num_examples=20):    \n    plt.figure(figsize=(15, 15))\n\n    for ind, (X, y) in enumerate(dataloader):\n        if ind >= num_examples:\n            break\n        X, y = X.to(device), y.to(device)    \n        pred = model(X)\n        probs = F.softmax(pred, dim=1)\n        final_pred = torch.argmax(probs, dim=1)\n\n        plt.subplot(10, 10, ind + 1)\n        plt.axis(\"off\")\n        plt.text(0, -1, str(y[0].item()), fontsize=14, color='green')  # correct\n        plt.text(8, -1, str(final_pred[0].item()), fontsize=14, color='red')  # predicted\n\n        image = np.transpose(X[0].cpu().numpy(), (1, 2, 0))  # Convert tensor to numpy array and rearrange dimensions\n\n        if image.shape[-1] == 1:  # If the image is grayscale, convert to RGB\n            image = np.squeeze(image)\n            plt.imshow(image, cmap='gray')\n        else:\n            plt.imshow(image)\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:50:18.685210Z","iopub.execute_input":"2023-05-28T21:50:18.686835Z","iopub.status.idle":"2023-05-28T21:50:18.696714Z","shell.execute_reply.started":"2023-05-28T21:50:18.686796Z","shell.execute_reply":"2023-05-28T21:50:18.695717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_errors(model, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:50:18.697921Z","iopub.execute_input":"2023-05-28T21:50:18.698320Z","iopub.status.idle":"2023-05-28T21:50:19.936459Z","shell.execute_reply.started":"2023-05-28T21:50:18.698288Z","shell.execute_reply":"2023-05-28T21:50:19.935483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_training_history(train_history, val_history):\n    plt.subplot(2, 1, 1)\n    plt.title('Cross Entropy Loss')\n    plt.plot(train_history['loss'], label='train')\n    plt.plot(val_history['loss'], label='val')\n    plt.legend(loc='best')\n\n    plt.subplot(2, 1, 2)\n    plt.title('Classification Accuracy')\n    plt.plot(train_history['accuracy'], label='train')\n    plt.plot(val_history['accuracy'], label='val')\n\n    plt.tight_layout()\n    plt.legend(loc='best')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:50:19.937594Z","iopub.execute_input":"2023-05-28T21:50:19.937936Z","iopub.status.idle":"2023-05-28T21:50:19.947016Z","shell.execute_reply.started":"2023-05-28T21:50:19.937909Z","shell.execute_reply":"2023-05-28T21:50:19.945763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training_history(train_history, val_history)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:50:19.948593Z","iopub.execute_input":"2023-05-28T21:50:19.949348Z","iopub.status.idle":"2023-05-28T21:50:20.444735Z","shell.execute_reply.started":"2023-05-28T21:50:19.949314Z","shell.execute_reply":"2023-05-28T21:50:20.443489Z"},"trusted":true},"execution_count":null,"outputs":[]}]}